If you want to expose the application running on the pod, you will use service. Service is similar to load balancers. It
controls the inflow of external traffic.

Pods are mortal, each pods have its own ip address, however in a deployment, the set of pods running in one moment in time
could be different from the set of pods running that same application few moments later.

That is why services are needed. They even a static endpoint to avoid the ephemeral pods problem. That is the services are
like permanent components in the node that won't change, as long as they dont change, we can always access the pods via the labels
when they are created.

Types of services:

    ClusterIP:
        This is the default service type. It exposes the service on an internal IP address reachable only within
        the cluster. It allows communication between different components of an application within the cluster.

    NodePort:
        This service type exposes the service on a static port on each node in the cluster. It creates a ClusterIP
        service and makes it accessible from outside the cluster by mapping a port on the node's IP address to the
        service. NodePort services are typically used for accessing services externally during development or testing.

    LoadBalancer:
        This service type creates an external load balancer (e.g., cloud provider's load balancer) and assigns
        a unique external IP address to the service. It allows traffic to be distributed across multiple pods
        and makes the service accessible from outside the cluster. LoadBalancer services are typically used in cloud
        environments to expose services to the internet.

    ExternalName:
        This maps the service to an external dns name, like a db



There is always a service in front of pods that routes the traffic, it has the frontend port which the port of the service,
and a backend port which is the port of the pods. It knows the appropriate backend port to route the request to by
using labels.


So whenever pods are created, the kubelet invokes the CNI plugins assigns  ip address to the pod, however the kube-proxy
creates a forwarding rule, that whenever you access a service via the ip and pod, forward the traffic to the list of
pods attached to the service.
Make usre ip range of ip does not overlay with the ip for service when configuring it in the kube-proxy

kubectl logs agent_cni -n kube-system # to see the range of ip for pods
 To see ip for the service its in the kube  api server manifest
